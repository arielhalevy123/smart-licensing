import os
import json
from docx import Document
from openai import OpenAI

# ğŸ“Œ ×•×“× ×©×™×© ×œ×š ××©×ª× ×” ×¡×‘×™×‘×” OPENAI_API_KEY
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# âš™ï¸ ×¤×¨×˜×™ ×”××©×ª××© â€“ ×“×•×’××” ×‘×¨×•×¨×”
user_input = {
    "business_name": "×××¤×™×™×ª ×—×œ×•×",
    "business_type": "bakery",   # ××¤×©×¨×•×™×•×ª: cafe, food_truck, restaurant, bar, bakery, catering
    "area_sqm": 80,
    "seating_capacity": 12,
    "employees": 5,
    "city": "×ª×œ ××‘×™×‘",
    "has_gas": True,
    "serves_meat": False,
    "has_delivery": True,
    "has_alcohol": False
}

# ğŸ“ ×¡×•×’×™ ×”×¢×¡×§×™× ×”××¤×©×¨×™×™×
BUSINESS_TYPES = ["cafe", "food_truck", "restaurant", "bar", "bakery", "catering"]

# ğŸ“ ×§×˜×’×•×¨×™×•×ª ××¤×©×¨×™×•×ª
CATEGORIES = [
    "×‘×¨×™××•×ª ×•×ª×‘×¨×•××”",
    "×‘×˜×™×—×•×ª ××©",
    "×¨×™×©×•×™ ×•×ª×›× ×•×Ÿ",
    "×¡×‘×™×‘×” ×•×¤×¡×•×œ×ª",
    "×ª×¤×¢×•×œ ×•× ×™×”×•×œ ×¢×•×‘×“×™×",
    "××—×¨"
]

# ğŸ“ ×˜×‘×œ×” ×©×œ ×©×“×•×ª ××¤×©×¨×™×™× ×œ×—×•×§×™×
FIELDS_TABLE = """
×©×“×•×ª ××¤×©×¨×™×™× ×œ×¡×™×•×•×’ ×—×•×§:
- business_type: cafe, food_truck, restaurant, bar, bakery, catering
- has_gas: true / false
- serves_meat: true / false
- has_delivery: true / false
- has_alcohol: true / false
- area_sqm: ××¡×¤×¨ (×˜×•×•×—×™× ×œ×“×•×’××”: ××ª×—×ª ×œ-50, ××¢×œ 200)
- seating_capacity: ××¡×¤×¨ (×˜×•×•×—×™× ×œ×“×•×’××”: ×¢×“ 20, ××¢×œ 100)
- employees: ××¡×¤×¨ (×˜×•×•×—×™× ×œ×“×•×’××”: ××¢×œ 10 ×¢×•×‘×“×™×)
- city: ××¤×©×¨ ×œ×”×ª× ×•×ª ×‘×¢×™×¨ ××¡×•×™××ª, ×× ×”×—×•×§ ×§×©×•×¨ ×œ×¨×©×•×ª ××§×•××™×ª
"""

def extract_text_from_docx(docx_path):
    """×§×¨×™××ª ×›×œ ×”×˜×§×¡×˜ ×•×”×˜×‘×œ××•×ª ××§×•×‘×¥ Word"""
    doc = Document(docx_path)
    full_text = []

    for para in doc.paragraphs:
        if para.text.strip():
            full_text.append(para.text.strip())

    for table in doc.tables:
        for row in table.rows:
            row_data = [cell.text.strip() for cell in row.cells if cell.text.strip()]
            if row_data:
                full_text.append(" | ".join(row_data))

    return "\n".join(full_text)

def convert_rules_with_ai(text, start_id=1):
    """×©×•×œ×— ×—×œ×§ ×˜×§×¡×˜ ×œ-ChatGPT ×•××—×–×™×¨ JSON"""
    prompt = f"""
××ª×” ××§×‘×œ ×§×˜×¢ ××ª×•×š ×§×•×‘×¥ ×¢× ×—×•×§×™× ×•×“×¨×™×©×•×ª.

× ×ª×•× ×™ ×”×¢×¡×§ ×œ×“×•×’××”:
{json.dumps(user_input, ensure_ascii=False, indent=2)}

×¡×•×’×™ ×¢×¡×§×™× ××¤×©×¨×™×™×:
{BUSINESS_TYPES}

×§×˜×’×•×¨×™×•×ª ××¤×©×¨×™×•×ª:
{CATEGORIES}

{FIELDS_TABLE}

×”××‘× ×” ×©×œ ×›×œ ×—×•×§:
{{
  "id": "RXXX",
  "title": "×©× ×”×—×•×§",
  "category": "×‘×¨×™××•×ª ×•×ª×‘×¨×•××” / ×‘×˜×™×—×•×ª ××© / ×¨×™×©×•×™ ×•×ª×›× ×•×Ÿ / ×¡×‘×™×‘×” ×•×¤×¡×•×œ×ª / ×ª×¤×¢×•×œ ×•× ×™×”×•×œ ×¢×•×‘×“×™× / ××—×¨",
  "applies_when": {{
    "business_type": ["restaurant", "bar"],
    "has_gas": [true, false],
    "serves_meat": [true, false],
    "has_delivery": [true, false],
    "has_alcohol": [true, false],
    "min_area": null,
    "max_area": null,
    "seating_capacity": null,
    "employees": null,
    "city": null
  }},
  "actions": ["×¤×¢×•×œ×” 1", "×¤×¢×•×œ×” 2"],
  "priority": "×§×¨×™×˜×™/×’×‘×•×”/×‘×™× ×•× ×™/× ××•×š",
  "estimated_cost": "×¢×œ×•×ª ××©×•×¢×¨×ª (â‚ª ××• '×œ×œ× ×¢×œ×•×ª × ×•×¡×¤×ª')"
}}

×“×’×©×™× ×—×©×•×‘×™×:
- ×¡×•×•×’ ×›×œ ×—×•×§ ×œ×§×˜×’×•×¨×™×” ×¨×œ×•×•× ×˜×™×ª ××—×ª ××ª×•×š ×”×¨×©×™××”.
- ×™×™×ª×›×Ÿ ×©×—×•×§ ×™×ª××™× ×œ×™×•×ª×¨ ××¡×•×’ ×¢×¡×§ ××—×“ â†’ ×¨×©×•× ××ª ×›×•×œ×.
- ×× ×”×—×•×§ ×ª×œ×•×™ ×‘×’×–/×‘×©×¨/××œ×›×•×”×•×œ/××©×œ×•×—×™× â†’ ×¦×™×™×Ÿ ×–××ª ×‘-applies_when.
- ×× ×–×” ×›×œ×œ ×›×œ×œ×™ (×›××• ×ª×œ×™×™×ª ×¨×™×©×™×•×Ÿ) â†’ business_type = ×›×œ {BUSINESS_TYPES}.
- ×”×•×¡×£ ×¢×œ×•×ª ××©×•×¢×¨×ª ×¨×™××œ×™×ª (××• "×œ×œ× ×¢×œ×•×ª × ×•×¡×¤×ª").
- ×—×•×‘×” ×œ××¡×¤×¨ ×‘×¨×¦×£ (R0001, R0002...).
- ××œ ×ª×¡×ª×¤×§ ×‘×“×•×’××” ××—×ª, ×ª×¡×•×•×’ ×œ×¤×™ ×”×”×™×’×™×•×Ÿ ×©×œ×š.
- ×”×—×–×¨ ××š ×•×¨×§ JSON ×ª×§×™×Ÿ.
- ×× ××™×Ÿ ×—×•×§×™× ×‘×§×˜×¢ â†’ ×”×—×–×¨ {{"rules": []}} ×‘×œ×‘×“.

×§×˜×¢ ××ª×•×š ×”×§×•×‘×¥:
{text}
    """

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    ai_text = response.choices[0].message.content
    return json.loads(ai_text)

def split_text(text, chunk_size=5000):
    """×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ×—×ª×™×›×•×ª ×§×˜× ×•×ª ×™×•×ª×¨"""
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

if __name__ == "__main__":
    docx_file = "18-07-2022_4.2A.docx"
    output_file = "rules.json"

    print("ğŸ“‚ ×§×•×¨× ××ª ×”×§×•×‘×¥...")
    text = extract_text_from_docx(docx_file)

    chunks = split_text(text, chunk_size=5000)
    print(f"âœ‚ï¸ ×”×§×•×‘×¥ ×¤×•×¦×œ ×œ-{len(chunks)} ×—×œ×§×™×")

    # âœ‚ï¸ ×¢×™×‘×•×“ ×¨×§ ×—×¦×™ ×§×•×‘×¥
    half_index = max(1, len(chunks) // 2)
    chunks = chunks[:half_index]
    print(f"ğŸ“‚ ××¢×‘×“ ×¨×§ {len(chunks)} ×—×œ×§×™× (×—×¦×™ ×§×•×‘×¥)")

    all_rules = {"rules": []}
    current_id = 1

    for i, chunk in enumerate(chunks, start=1):
        print(f"ğŸ¤– ×©×•×œ×— ×œ-ChatGPT ×—×œ×§ {i}/{len(chunks)}...")
        try:
            ai_data = convert_rules_with_ai(chunk, start_id=current_id)

            rules = ai_data.get("rules", [])
            for j, rule in enumerate(rules, start=0):
                rule["id"] = f"R{current_id + j:04d}"
            current_id += len(rules)

            all_rules["rules"].extend(rules)
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×—×œ×§ {i}: {e}")

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_rules, f, ensure_ascii=False, indent=2)

    print(f"âœ… ×§×•×‘×¥ JSON × ×•×¦×¨ ×‘×”×¦×œ×—×”: {output_file}")
