import os
import json
from docx import Document
from openai import OpenAI

# ğŸ“Œ ×•×“× ×©×™×© ×œ×š ××©×ª× ×” ×¡×‘×™×‘×” OPENAI_API_KEY
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_text_from_docx(docx_path):
    """×§×¨×™××ª ×›×œ ×”×˜×§×¡×˜ ×•×”×˜×‘×œ××•×ª ××§×•×‘×¥ Word"""
    doc = Document(docx_path)
    full_text = []

    # ×¤×¡×§××•×ª ×¨×’×™×œ×•×ª
    for para in doc.paragraphs:
        if para.text.strip():
            full_text.append(para.text.strip())

    # ×˜×‘×œ××•×ª
    for table in doc.tables:
        for row in table.rows:
            row_data = [cell.text.strip() for cell in row.cells if cell.text.strip()]
            if row_data:
                full_text.append(" | ".join(row_data))

    return "\n".join(full_text)


def convert_rules_with_ai(text):
    """×©×•×œ×— ×—×œ×§ ×˜×§×¡×˜ ×œ-ChatGPT ×•××—×–×™×¨ JSON"""
    prompt = f"""
××ª×” ××§×‘×œ ×§×˜×¢ ××ª×•×š ×§×•×‘×¥ ×¢× ×—×•×§×™× ×•×“×¨×™×©×•×ª (×›×•×œ×œ ×˜×‘×œ××•×ª ×•×¤×¡×§××•×ª).
×”××˜×¨×”: ×œ×”×—×–×™×¨ JSON ××•×‘× ×” ×›×š ×©×›×œ ×—×•×§ ×™×•×¦×’ ×›×š:

{{
  "id": "R001",
  "title": "×©× ×”×—×•×§",
  "applies_when": {{
    "business_type": ["food_truck", "restaurant", "cafe"],
    "food_type": ["×‘×©×¨", "×“×’×™×", "×‘×™×¦×™×"],
    "min_area": null,
    "max_area": null,
    "seating_capacity": null
  }},
  "actions": ["×¤×¢×•×œ×” 1", "×¤×¢×•×œ×” 2", "×¤×¢×•×œ×” 3"],
  "priority": "×§×¨×™×˜×™"
}}

×—×©×•×‘:
- ×›×œ ×—×•×§ ×—×™×™×‘ ×œ×”×™×•×ª ×¨×©×•××” × ×¤×¨×“×ª.
- ×× ×”×§×˜×¢ ×§×¦×¨ ×•××™×Ÿ ×‘×• ×—×•×§×™× â€“ ×”×—×–×¨ {{"rules": []}} ×‘×œ×‘×“.

×§×˜×¢ ××ª×•×š ×”×§×•×‘×¥:
{text}
    """

    response = client.chat.completions.create(
        model="gpt-4.1",   # ××¤×©×¨ ×’× "gpt-4o"
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    ai_text = response.choices[0].message.content
    return json.loads(ai_text)


def split_text(text, chunk_size=5000):
    """×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ×—×ª×™×›×•×ª ×§×˜× ×•×ª ×™×•×ª×¨"""
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]


if __name__ == "__main__":
    docx_file = "18-07-2022_4.2A.docx"   # â† ×©× ×”×§×•×‘×¥ ×©×œ×š
    output_file = "rules.json"

    print("ğŸ“‚ ×§×•×¨× ××ª ×”×§×•×‘×¥...")
    text = extract_text_from_docx(docx_file)

    chunks = split_text(text, chunk_size=5000)
    print(f"âœ‚ï¸ ×”×§×•×‘×¥ ×¤×•×¦×œ ×œ-{len(chunks)} ×—×œ×§×™×")

    all_rules = {"rules": []}

    for i, chunk in enumerate(chunks, start=1):
        print(f"ğŸ¤– ×©×•×œ×— ×œ-ChatGPT ×—×œ×§ {i}/{len(chunks)}...")
        try:
            ai_data = convert_rules_with_ai(chunk)
            all_rules["rules"].extend(ai_data.get("rules", []))
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×—×œ×§ {i}: {e}")

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_rules, f, ensure_ascii=False, indent=2)

    print(f"âœ… ×§×•×‘×¥ JSON × ×•×¦×¨ ×‘×”×¦×œ×—×”: {output_file}")
