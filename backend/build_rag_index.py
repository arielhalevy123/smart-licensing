import os
import json
import re
from docx import Document
from openai import OpenAI

# Configuration
DOCX_PATH = "18-07-2022_4.2A.docx"
INDEX_OUTPUT_PATH = "backend/rag_index.json"
PREVIEW_PATH = "rag_sections_preview.txt"   # ×¨×§ ×œ×¦×•×¨×š ×‘×“×™×§×” ×× ×•×©×™×ª
EMBEDDING_MODEL = "text-embedding-3-small"

# Initialize OpenAI
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âš ï¸  Warning: OPENAI_API_KEY not found in environment variables.")

client = OpenAI(api_key=api_key)

# ×¡×¢×™×£ ××©×¤×˜×™: 1.  / 1.1. / 1.2.3. / 2.10.4.1
SECTION_RE = re.compile(r'^\s*(\d+(\.\d+)*\.?)\s+')

def extract_blocks_from_docx(path):
    """
    ××—×–×™×¨ ×¨×©×™××” ×©×œ ×‘×œ×•×§×™× ×˜×§×¡×˜×•××œ×™×™× (×¤×¡×§××•×ª ×•×©×•×¨×•×ª ××˜×‘×œ××•×ª).
    ×›×œ ×‘×œ×•×§ ×”×•× ××—×¨×•×–×ª.
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"File not found: {path}")
    
    doc = Document(path)
    blocks = []

    # ×¤×¡×§××•×ª
    print("   ... Reading paragraphs ...")
    for para in doc.paragraphs:
        text = para.text.strip()
        if text:
            blocks.append(text)

    # ×˜×‘×œ××•×ª
    print("   ... Reading tables ...")
    for table in doc.tables:
        for row in table.rows:
            row_text = " | ".join(
                cell.text.strip() for cell in row.cells if cell.text.strip()
            )
            if row_text:
                blocks.append(row_text)

    print(f"âœ… Collected {len(blocks)} text blocks (paragraphs + tables)")
    return blocks

def split_blocks_to_sections(blocks):
    """
    ×—×•×ª×š ××ª ×¨×©×™××ª ×”×‘×œ×•×§×™× ×œ×¡×¢×™×¤×™× ×œ×¤×™ ××¡×¤×•×¨:
    ×›×œ ×‘×œ×•×§ ×©××ª×—×™×œ ×‘- 1. / 1.1. / 1.2.3. ×•×›×•' ×¤×•×ª×— ×¡×¢×™×£ ×—×“×©.
    ×›×œ ××” ×©×‘× ××—×¨ ×›×š ×•×œ× ××ª×—×™×œ ×‘××¡×¤×•×¨ â€“ ××¦×˜×¨×£ ×œ×¡×¢×™×£ ×”××—×¨×•×Ÿ.
    """
    sections = []
    current_id = None
    current_parts = []

    for block in blocks:
        m = SECTION_RE.match(block)
        if m:
            # ×”×ª×—×œ×” ×©×œ ×¡×¢×™×£ ×—×“×©
            # ×§×•×“× × ×¡×’×•×¨ ××ª ×”×§×•×“× ×× ×§×™×™×
            if current_id is not None and current_parts:
                full_text = "\n".join(current_parts).strip()
                if full_text:
                    sections.append({
                        "id": current_id,
                        "chunk": full_text
                    })

            # ×—×™×œ×•×¥ ×”××¡×¤×•×¨ (×œ××©×œ "1.7.2.3")
            sec_id = m.group(1).rstrip(".")
            current_id = sec_id
            current_parts = [block]
        else:
            # ×©×•×¨×” ×©×××©×™×›×” ××ª ×”×¡×¢×™×£ ×”××—×¨×•×Ÿ
            if current_id is None:
                # ×˜×§×¡×˜ ×œ×¤× ×™ ×¡×¢×™×£ ×¨××©×•×Ÿ â€“ ××¤×©×¨ ×œ×“×œ×’, ××• ×œ×©××•×¨ ×œ×¡×¢×™×£ INTRO
                # ×›××Ÿ ××“×œ×’×™× ×›×“×™ ×œ× ×œ×œ×›×œ×š ××ª ×”××™× ×“×§×¡.
                continue
            current_parts.append(block)

    # ×œ×¡×’×•×¨ ××ª ×”×¡×¢×™×£ ×”××—×¨×•×Ÿ
    if current_id is not None and current_parts:
        full_text = "\n".join(current_parts).strip()
        if full_text:
            sections.append({
                "id": current_id,
                "chunk": full_text
            })

    print(f"âœ‚ï¸  Split into {len(sections)} numbered sections.")
    return sections

def save_preview(sections, path=PREVIEW_PATH):
    """
    ×©×•××¨ ×§×•×‘×¥ ×˜×§×¡×˜ ×œ×§×¨×™××” ×× ×•×©×™×ª, ×›×“×™ ×©×ª×¨××” ××™×š ×”×¡×§×¨×™×¤×˜ ×—×ª×š ××ª ×”×¡×¢×™×¤×™×.
    ×œ× ×—×•×‘×” ×‘×©×‘×™×œ ×”××¢×¨×›×ª, ××‘×œ ×××•×“ ×¢×•×–×¨ ×œ×‘×“×™×§×”.
    """
    with open(path, "w", encoding="utf-8") as f:
        for s in sections:
            f.write(f"===== ×¡×¢×™×£ {s['id']} =====\n")
            f.write(s["chunk"])
            f.write("\n\n")
    print(f"ğŸ” Preview saved to {path}")

def generate_embeddings(sections):
    """
    ××™×™×¦×¨ embeddings ×œ×›×œ ×¡×¢×™×£ ×•××—×–×™×¨ ××ª ××•×ª×” ×¨×©×™××ª ×¡×¢×™×¤×™×
    ×¢× ×©×“×” × ×•×¡×£ "embedding" ×‘×›×œ ××•×‘×™×™×§×˜.
    """
    print(f"ğŸš€ Generating embeddings for {len(sections)} sections...")
    batch_size = 20
    idx = 0

    for i in range(0, len(sections), batch_size):
        batch = sections[i:i+batch_size]
        texts = [s["chunk"] for s in batch]

        try:
            response = client.embeddings.create(
                input=texts,
                model=EMBEDDING_MODEL
            )
            for j, item in enumerate(response.data):
                sections[idx]["embedding"] = item.embedding
                idx += 1
            print(f"   Processed batch {i // batch_size + 1}/{(len(sections) + batch_size - 1) // batch_size}")
        except Exception as e:
            print(f"âŒ Error processing batch starting at index {i}: {e}")

    missing = [s for s in sections if "embedding" not in s]
    if missing:
        print(f"âš ï¸ Warning: {len(missing)} sections have no embedding")
    return sections

def main():
    print("ğŸ“‚ Starting RAG Index Build Process (by legal sections)...")

    try:
        # 1. Load raw blocks (paragraphs + tables)
        print(f"ğŸ“– Loading document: {DOCX_PATH}")
        blocks = extract_blocks_from_docx(DOCX_PATH)

        # 2. Split into logical sections by numbering
        sections = split_blocks_to_sections(blocks)

        # 3. Save preview for manual inspection
        save_preview(sections)

        # 4. Generate embeddings
        sections_with_emb = generate_embeddings(sections)

        # 5. Save final index
        print(f"ğŸ’¾ Saving index to {INDEX_OUTPUT_PATH}...")
        os.makedirs(os.path.dirname(INDEX_OUTPUT_PATH), exist_ok=True)
        with open(INDEX_OUTPUT_PATH, "w", encoding="utf-8") as f:
            json.dump(sections_with_emb, f, ensure_ascii=False, indent=2)

        print("ğŸ‰ RAG Index built successfully!")

    except Exception as e:
        print(f"âŒ Critical Error: {e}")

if __name__ == "__main__":
    main()